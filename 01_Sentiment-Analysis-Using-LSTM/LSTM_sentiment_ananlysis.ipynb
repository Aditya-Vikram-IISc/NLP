{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "_llb9DFrohVy",
        "outputId": "010c68ae-149c-4e96-d4d1-46b36d5462f6"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'text_processing'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-343af66dd924>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfigparser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtext_processing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mread_data_from_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_word_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_words_to_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_and_truncate_reviews\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSentimentDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSentimentLSTM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'text_processing'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from numpy import random\n",
        "import configparser\n",
        "from text_processing import read_data_from_folder, get_word_count, map_words_to_index, pad_and_truncate_reviews\n",
        "from utils import SentimentDataset, SentimentLSTM, accuracy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the INI configuration file\n",
        "config = configparser.ConfigParser()\n",
        "config.read(\"config.ini\")\n",
        "\n",
        "# Get the values for text processing\n",
        "SEQUENCE_MAX_CUTOFF_LENGTH = int(config[\"TEXT_PROCESSING\"][\"SEQUENCE_MAX_CUTOFF_LENGTH\"]) # Used review length analysis to get the value\n",
        "SEQUENCE_MIN_CUTOFF_LENGTH = int(config[\"TEXT_PROCESSING\"][\"SEQUENCE_MIN_CUTOFF_LENGTH\"])  # All reviews need to be greater than this\n",
        "\n",
        "\n",
        "# Model Params & Training Params\n",
        "LEARNING_RATE = float(config[\"MODEL_TRAINING\"][\"LEARNING_RATE\"])\n",
        "EPOCHS = int(config[\"MODEL_TRAINING\"][\"EPOCHS\"])\n",
        "CLIP = int(config[\"MODEL_TRAINING\"][\"CLIP\"])\n",
        "BATCH_SIZE = int(config[\"MODEL_TRAINING\"][\"BATCH_SIZE\"])\n",
        "\n",
        "# Model Hyperparameters\n",
        "OUTPUT_SIZE = int(config[\"MODEL_HYPERPARAMS\"][\"OUTPUT_SIZE\"])\n",
        "EMBEDDING_DIM = int(config[\"MODEL_HYPERPARAMS\"][\"EMBEDDING_DIM\"])\n",
        "LSTM_HIDDEN_DIM = int(config[\"MODEL_HYPERPARAMS\"][\"LSTM_HIDDEN_DIM\"])\n",
        "LSTM_NLAYERS = int(config[\"MODEL_HYPERPARAMS\"][\"LSTM_NLAYERS\"])\n",
        "DROP_PROP = float(config[\"MODEL_HYPERPARAMS\"][\"DROP_PROP\"])"
      ],
      "metadata": {
        "id": "p3v_0I-Foqy9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 01. Read the data"
      ],
      "metadata": {
        "id": "swWGyJzBotjL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### read all the data in a folder. Output is a tuple(list[reviews], list[ratings])\n",
        "\n",
        "train_pos_reviews, train_pos_ratings  = read_data_from_folder(folderpath = \"train/pos\")\n",
        "train_neg_reviews, train_neg_ratings  = read_data_from_folder(folderpath = \"train/neg\")\n",
        "test_pos_reviews, test_pos_ratings  = read_data_from_folder(folderpath = \"test/pos\")\n",
        "test_neg_reviews, test_neg_ratings  = read_data_from_folder(folderpath = \"test/neg\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "YHmRNj03oqv0",
        "outputId": "5043831e-43c6-4461-899f-eeeaacb8f7a7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'read_data_from_folder' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-70dcfecb7974>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m### read all the data in a folder. Output is a tuple(list[reviews], list[ratings])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_pos_reviews\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_pos_ratings\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mread_data_from_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolderpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"train/pos\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtrain_neg_reviews\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_neg_ratings\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mread_data_from_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolderpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"train/neg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_pos_reviews\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pos_ratings\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mread_data_from_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolderpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"test/pos\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'read_data_from_folder' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### get training and test datasets by combining pos and neg data\n",
        "\n",
        "train_reviews = train_pos_reviews + train_neg_reviews\n",
        "train_ratings = train_pos_ratings + train_neg_ratings\n",
        "test_reviews = test_pos_reviews + test_neg_reviews\n",
        "test_ratings = test_pos_ratings + test_neg_ratings"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "GlhH-IkOoquI",
        "outputId": "5c56c9cc-a230-427e-ab2a-66e7b70528c0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_pos_reviews' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-e1068b5a2c1e>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m### get training and test datasets by combining pos and neg data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_reviews\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_pos_reviews\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtrain_neg_reviews\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtrain_ratings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_pos_ratings\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtrain_neg_ratings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_reviews\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_pos_reviews\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtest_neg_reviews\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_pos_reviews' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Get a perspective of data shape\n",
        "print(\"Total count of rating reviews foir training\", len(train_reviews))\n",
        "print(\"Total count of rating ratings foir training\", len(train_ratings))\n",
        "print(\"Total count of rating reviews foir testing\", len(test_reviews))\n",
        "print(\"Total count of rating ratings foir testing\", len(test_ratings))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "FHoYC-P1oqsE",
        "outputId": "385cfd85-0ca8-43dc-8d5b-527749667121"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_reviews' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-ddf678a307ec>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m### Get a perspective of data shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Total count of rating reviews foir training\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_reviews\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Total count of rating ratings foir training\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ratings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Total count of rating reviews foir testing\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_reviews\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Total count of rating ratings foir testing\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_ratings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_reviews' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 02. Tokenise the data - Reviews and Ratings\n",
        "\n",
        "* Map the words in the reviews to some integer indexing\n",
        "* Similarly map the ratings to binary values"
      ],
      "metadata": {
        "id": "YZA6HiblozZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Get a word count dictionary\n",
        "\n",
        "words_count = get_word_count(train_reviews)\n",
        "distinct_words_total = len(words_count)\n",
        "\n",
        "words_count_sorted = words_count.most_common(distinct_words_total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "tdaW-i3OoqqJ",
        "outputId": "535e397f-90e5-45dd-d815-c0619ff24790"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'get_word_count' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-5dafcb160367>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m### Get a word count dictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mwords_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_word_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_reviews\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdistinct_words_total\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'get_word_count' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Get a mapper to map words to integer indexes\n",
        "### As we are going to do padding for shorter reviews and conventional choice for padding is 0. So we need to start this indexing from 1. OOV words in test dataset are dropped\n",
        "\n",
        "\n",
        "## Create a mapping of words to index\n",
        "vocab_to_int = {word:i+1 for i, (word,_) in enumerate(words_count_sorted)}\n",
        "\n",
        "## map the words to index in train and test reviews\n",
        "train_reviews_encoded = [map_words_to_index(review, vocab_to_int) for review in train_reviews]\n",
        "test_reviews_encoded = [map_words_to_index(review, vocab_to_int) for review in test_reviews]\n",
        "\n",
        "## encode the labels as well\n",
        "train_ratings_encoded = [1 if rating >= 7 else 0 for rating in train_ratings]\n",
        "test_ratings_encoded = [1 if rating >= 7 else 0 for rating in test_ratings]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "khWLKVFYo3XH",
        "outputId": "79feaf56-12e9-49cc-df27-4a45fc6e335f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'words_count_sorted' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-367aac3a4552>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m## Create a mapping of words to index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mvocab_to_int\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords_count_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m## map the words to index in train and test reviews\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'words_count_sorted' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 03. Padding/ Truncating the reviews for training"
      ],
      "metadata": {
        "id": "GoDlyN4lo506"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Get a grasp of review lengths for training in batches\n",
        "\n",
        "train_reviews_length = [len(re) for re in train_reviews_encoded]\n",
        "\n",
        "plt.hist(train_reviews_length)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "g80obhr5o3VK",
        "outputId": "232ecdd6-56ac-4a08-afe2-b08eebc8e46f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_reviews_encoded' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-9927f001404a>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m### Get a grasp of review lengths for training in batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_reviews_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mre\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_reviews_encoded\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_reviews_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_reviews_encoded' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Get basic statistics\n",
        "\n",
        "print(\"Mean of the review length:\", int(np.mean(train_reviews_length)))\n",
        "print(\"25th percentile of the review length:\", np.percentile(train_reviews_length, 25))\n",
        "print(\"50th percentile of the review length:\", np.percentile(train_reviews_length, 50))\n",
        "print(\"75th percentile of the review length:\", np.percentile(train_reviews_length, 75))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "BohoevF3o3Te",
        "outputId": "36baf210-69cb-407a-fe8a-fda98e807e3b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_reviews_length' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-b5267b222e43>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m### Get basic statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Mean of the review length:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_reviews_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"25th percentile of the review length:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpercentile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_reviews_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"50th percentile of the review length:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpercentile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_reviews_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_reviews_length' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Guess a review length of 256 should be good enough\n",
        "### Remove review of length 0, if there\n",
        "\n",
        "train_reviews_encoded = [train_reviews_encoded[index] for index, length in enumerate(train_reviews_length) if length >= SEQUENCE_MIN_CUTOFF_LENGTH]\n",
        "train_ratings_encoded = [train_ratings_encoded[index] for index, length in enumerate(train_reviews_length) if length >= SEQUENCE_MIN_CUTOFF_LENGTH]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "B-1AVPnso3Ra",
        "outputId": "0145e3bf-7ff1-4ac7-a44f-a20b02a65261"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_reviews_length' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-91bef3a8099b>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m### Remove review of length 0, if there\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain_reviews_encoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtrain_reviews_encoded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_reviews_length\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlength\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mSEQUENCE_MIN_CUTOFF_LENGTH\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtrain_ratings_encoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtrain_ratings_encoded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_reviews_length\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlength\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mSEQUENCE_MIN_CUTOFF_LENGTH\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_reviews_length' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### For reviews shorter than SEQUENCE_LENGTH, we will pad with 0s. For reviews longer than seq_length we will truncate them to the first SEQUENCE_LENGTH words. SEQUENCE_LENGTH is same as number of timesteps in LSTM\n",
        "\n",
        "# pad/ truncate the reviews to a uniform size of SEQUENCE_LENGTH. Output id array of shape #num_reviews * SEQUENCE_LENGTH\n",
        "train_reviews_encoded_arr = pad_and_truncate_reviews(train_reviews_encoded, SEQUENCE_MAX_CUTOFF_LENGTH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "bGwD3J7yo3PO",
        "outputId": "ebbdad5c-098d-45a2-e280-6951fc4e460c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'pad_and_truncate_reviews' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-3dc0297460eb>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# pad/ truncate the reviews to a uniform size of SEQUENCE_LENGTH. Output id array of shape #num_reviews * SEQUENCE_LENGTH\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain_reviews_encoded_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_and_truncate_reviews\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_reviews_encoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSEQUENCE_MAX_CUTOFF_LENGTH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'pad_and_truncate_reviews' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 04. Train validation split"
      ],
      "metadata": {
        "id": "QIlZvAYwpAW_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### As first 12500 reviews are positive and next 12500 reviews are negative. I have to uniquely select the reviews to ensure 50-50 balance of reviews in train and validation\n",
        "\n",
        "split_frac = 0.8\n",
        "\n",
        "train_index = np.concatenate(\n",
        "    (random.choice(list(range(0,12500)), size = int(split_frac*12500), replace= False),\n",
        "     random.choice(list(range(12500,25000)), size = int(split_frac*12500), replace= False),\n",
        "    ), axis = 0)\n",
        "\n",
        "validation_index = np.setdiff1d(np.array(list(range(0,25000))), train_index)\n",
        "\n",
        "\n",
        "# Get the train and validation dataset\n",
        "train_reviews_encodedX = np.take(train_reviews_encoded_arr, train_index, axis= 0)\n",
        "train_ratings_encodedy = np.take(np.array(train_ratings_encoded, dtype = int), train_index, axis= 0)\n",
        "\n",
        "valid_reviews_encodedX = np.take(train_reviews_encoded_arr, validation_index, axis= 0)\n",
        "valid_ratings_encodedy = np.take(np.array(train_ratings_encoded, dtype = int), validation_index, axis= 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "LnwDFBQBo2nd",
        "outputId": "e36cb196-019c-4350-a6de-7fa65db1601c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_reviews_encoded_arr' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-e43e767340dc>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Get the train and validation dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mtrain_reviews_encodedX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_reviews_encoded_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mtrain_ratings_encodedy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ratings_encoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_reviews_encoded_arr' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create custom Dataset and Dataloader for train and validation data\n",
        "\n",
        "train_dataset = SentimentDataset(train_reviews_encodedX, train_ratings_encodedy)\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "\n",
        "valid_dataset = SentimentDataset(valid_reviews_encodedX, valid_ratings_encodedy)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "Q6ukJP8eo2j9",
        "outputId": "25f914b7-2052-42e9-c7de-ce6d96456662"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'SentimentDataset' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-670932aad588>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# create custom Dataset and Dataloader for train and validation data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentimentDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_reviews_encodedX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_ratings_encodedy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'SentimentDataset' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 05. Create a model instanse"
      ],
      "metadata": {
        "id": "X_hLxzyUpErU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = SentimentLSTM(vocab_size = len(vocab_to_int),\n",
        "                      output_size = OUTPUT_SIZE,\n",
        "                      embedding_dim = EMBEDDING_DIM,\n",
        "                      hidden_dim = LSTM_HIDDEN_DIM,\n",
        "                      n_layers = LSTM_NLAYERS,\n",
        "                      drop_prob=DROP_PROP)\n",
        "\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "VP2Q3D6Lo2iQ",
        "outputId": "72a756ae-da91-4500-c72a-e8c6973f877d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'SentimentLSTM' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-9977edc4a105>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model = SentimentLSTM(vocab_size = len(vocab_to_int), \n\u001b[0m\u001b[1;32m      2\u001b[0m                       \u001b[0moutput_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOUTPUT_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                       \u001b[0membedding_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEMBEDDING_DIM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                       \u001b[0mhidden_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTM_HIDDEN_DIM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                       \u001b[0mn_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTM_NLAYERS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'SentimentLSTM' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 06. Training"
      ],
      "metadata": {
        "id": "naKX9iF3o2gU"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# loss and optimization functions\n",
        "lr= LEARNING_RATE\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "# training params\n",
        "epochs = EPOCHS # 3-4 is approx where I noticed the validation loss stop decreasing\n",
        "counter = 0\n",
        "print_every = 100\n",
        "clip= CLIP # gradient clipping"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "mPchbET_o2ev",
        "outputId": "65eb586f-0f01-415d-9360-cc8f754f8bdf"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'LEARNING_RATE' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-e1678d8f23ea>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# loss and optimization functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mLEARNING_RATE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBCELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'LEARNING_RATE' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# loss and optimization functions\n",
        "lr= LEARNING_RATE\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "# training params\n",
        "epochs = EPOCHS # 3-4 is approx where I noticed the validation loss stop decreasing\n",
        "clip= CLIP # gradient clipping\n",
        "\n",
        "epoch_tr_loss,epoch_vl_loss = [],[]\n",
        "epoch_tr_acc,epoch_vl_acc = [],[]\n",
        "\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    train_losses = []\n",
        "    train_acc = 0.0\n",
        "    model.train()\n",
        "    # initialize hidden state\n",
        "    h = model.init_hidden(BATCH_SIZE)\n",
        "    for inputs, labels in train_loader:\n",
        "\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        # Creating new variables for the hidden state, otherwise\n",
        "        # we'd backprop through the entire training history\n",
        "        h = tuple([each.data for each in h])\n",
        "\n",
        "        model.zero_grad()\n",
        "        output,h = model(inputs,h)\n",
        "\n",
        "        # calculate the loss and perform backprop\n",
        "        loss = criterion(output.squeeze(), labels.float())\n",
        "        loss.backward()\n",
        "        train_losses.append(loss.item())\n",
        "        # calculating accuracy\n",
        "        acc = accuracy(output,labels)\n",
        "        train_acc += acc\n",
        "        #`clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "\n",
        "    val_h = model.init_hidden(BATCH_SIZE)\n",
        "    val_losses = []\n",
        "    val_acc = 0.0\n",
        "    model.eval()\n",
        "    for inputs, labels in valid_loader:\n",
        "            val_h = tuple([each.data for each in val_h])\n",
        "\n",
        "\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "\n",
        "            output, val_h = model(inputs, val_h)\n",
        "            val_loss = criterion(output.squeeze(), labels.float())\n",
        "\n",
        "\n",
        "            val_losses.append(val_loss.item())\n",
        "\n",
        "            acc = accuracy(output,labels)\n",
        "            val_acc += acc\n",
        "\n",
        "    epoch_train_loss = np.mean(train_losses)\n",
        "    epoch_val_loss = np.mean(val_losses)\n",
        "    epoch_train_acc = train_acc/len(train_loader.dataset)\n",
        "    epoch_val_acc = val_acc/len(valid_loader.dataset)\n",
        "    epoch_tr_loss.append(epoch_train_loss)\n",
        "    epoch_vl_loss.append(epoch_val_loss)\n",
        "    epoch_tr_acc.append(epoch_train_acc)\n",
        "    epoch_vl_acc.append(epoch_val_acc)\n",
        "    print(f'Epoch {epoch+1}')\n",
        "    print(f'train_loss : {epoch_train_loss} val_loss : {epoch_val_loss}')\n",
        "    print(f'train_accuracy : {epoch_train_acc*100} val_accuracy : {epoch_val_acc*100}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "AnVO6veXo2c8",
        "outputId": "4b8180d0-79cc-4a41-d6ce-fcd1e4be3013"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'LEARNING_RATE' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-22e6bc386a52>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# loss and optimization functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mLEARNING_RATE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBCELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'LEARNING_RATE' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-5Uw8a-jo2bI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dt6C7A1Wo2Zk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "urpW-9fCo1mJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}