{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_llb9DFrohVy"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from numpy import random\n",
        "import configparser\n",
        "from text_processing import read_data_from_folder, get_word_count, map_words_to_index, pad_and_truncate_reviews\n",
        "from utils import SentimentDataset, SentimentLSTM, accuracy\n",
        "from test_utils import process_test_reviewx, predict_sentiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "p3v_0I-Foqy9"
      },
      "outputs": [],
      "source": [
        "# Read the INI configuration file\n",
        "config = configparser.ConfigParser()\n",
        "config.read(\"config.ini\")\n",
        "\n",
        "# Get the values for text processing\n",
        "SEQUENCE_MAX_CUTOFF_LENGTH = int(config[\"TEXT_PROCESSING\"][\"SEQUENCE_MAX_CUTOFF_LENGTH\"]) # Used review length analysis to get the value\n",
        "SEQUENCE_MIN_CUTOFF_LENGTH = int(config[\"TEXT_PROCESSING\"][\"SEQUENCE_MIN_CUTOFF_LENGTH\"])  # All reviews need to be greater than this\n",
        "\n",
        "\n",
        "# Model Params & Training Params\n",
        "LEARNING_RATE = float(config[\"MODEL_TRAINING\"][\"LEARNING_RATE\"])\n",
        "EPOCHS = int(config[\"MODEL_TRAINING\"][\"EPOCHS\"])\n",
        "CLIP = int(config[\"MODEL_TRAINING\"][\"CLIP\"])\n",
        "BATCH_SIZE = int(config[\"MODEL_TRAINING\"][\"BATCH_SIZE\"])\n",
        "\n",
        "# Model Hyperparameters\n",
        "OUTPUT_SIZE = int(config[\"MODEL_HYPERPARAMS\"][\"OUTPUT_SIZE\"])\n",
        "EMBEDDING_DIM = int(config[\"MODEL_HYPERPARAMS\"][\"EMBEDDING_DIM\"])\n",
        "LSTM_HIDDEN_DIM = int(config[\"MODEL_HYPERPARAMS\"][\"LSTM_HIDDEN_DIM\"])\n",
        "LSTM_NLAYERS = int(config[\"MODEL_HYPERPARAMS\"][\"LSTM_NLAYERS\"])\n",
        "DROP_PROP = float(config[\"MODEL_HYPERPARAMS\"][\"DROP_PROP\"])\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swWGyJzBotjL"
      },
      "source": [
        "## 01. Read the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "YHmRNj03oqv0"
      },
      "outputs": [],
      "source": [
        "# ### read all the data in a folder. Output is a tuple(list[reviews], list[ratings])\n",
        "\n",
        "train_pos_reviews, train_pos_ratings  = read_data_from_folder(folderpath = \"train/pos\")\n",
        "train_neg_reviews, train_neg_ratings  = read_data_from_folder(folderpath = \"train/neg\")\n",
        "test_pos_reviews, test_pos_ratings  = read_data_from_folder(folderpath = \"test/pos\")\n",
        "test_neg_reviews, test_neg_ratings  = read_data_from_folder(folderpath = \"test/neg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "GlhH-IkOoquI"
      },
      "outputs": [],
      "source": [
        "### get training and test datasets by combining pos and neg data\n",
        "\n",
        "train_reviews = train_pos_reviews + train_neg_reviews\n",
        "train_ratings = train_pos_ratings + train_neg_ratings\n",
        "test_reviews = test_pos_reviews + test_neg_reviews\n",
        "test_ratings = test_pos_ratings + test_neg_ratings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "FHoYC-P1oqsE"
      },
      "outputs": [],
      "source": [
        "### Get a perspective of data shape\n",
        "print(\"Total count of rating reviews foir training\", len(train_reviews))\n",
        "print(\"Total count of rating ratings foir training\", len(train_ratings))\n",
        "print(\"Total count of rating reviews foir testing\", len(test_reviews))\n",
        "print(\"Total count of rating ratings foir testing\", len(test_ratings))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZA6HiblozZX"
      },
      "source": [
        "## 02. Tokenise the data - Reviews and Ratings\n",
        "\n",
        "* Map the words in the reviews to some integer indexing\n",
        "* Similarly map the ratings to binary values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "tdaW-i3OoqqJ"
      },
      "outputs": [],
      "source": [
        "### Get a word count dictionary\n",
        "\n",
        "words_count = get_word_count(train_reviews)\n",
        "distinct_words_total = len(words_count)\n",
        "\n",
        "words_count_sorted = words_count.most_common(distinct_words_total)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "khWLKVFYo3XH"
      },
      "outputs": [],
      "source": [
        "### Get a mapper to map words to integer indexes\n",
        "### As we are going to do padding for shorter reviews and conventional choice for padding is 0. So we need to start this indexing from 1. OOV words in test dataset are dropped\n",
        "\n",
        "\n",
        "## Create a mapping of words to index\n",
        "vocab_to_int = {word:i+1 for i, (word,_) in enumerate(words_count_sorted)}\n",
        "\n",
        "## map the words to index in train and test reviews\n",
        "train_reviews_encoded = [map_words_to_index(review, vocab_to_int) for review in train_reviews]\n",
        "test_reviews_encoded = [map_words_to_index(review, vocab_to_int) for review in test_reviews]\n",
        "\n",
        "## encode the labels as well\n",
        "train_ratings_encoded = [1 if rating >= 7 else 0 for rating in train_ratings]\n",
        "test_ratings_encoded = [1 if rating >= 7 else 0 for rating in test_ratings]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GoDlyN4lo506"
      },
      "source": [
        "## 03. Padding/ Truncating the reviews for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "g80obhr5o3VK",
        "outputId": "232ecdd6-56ac-4a08-afe2-b08eebc8e46f"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjoAAAGdCAYAAAAbudkLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAuVElEQVR4nO3dfXBUVZ7/8U8DdgeUToCYdDIGCKA8SHh0jO0IypJNg1mVkd1FQEGNMDhhRgkiRhkMsLVhocBhRpS1fIhbA6JsaVRgkBDAiDQogQABSQkGo2s6zICkeTIQcn9/uLk/e3ky2knI4f2qulW593z79DmH2P3x9r0dh2VZlgAAAAzUoqkHAAAA0FAIOgAAwFgEHQAAYCyCDgAAMBZBBwAAGIugAwAAjEXQAQAAxiLoAAAAY7Vq6gE0pdraWn3zzTdq27atHA5HUw8HAAD8CJZl6dixY4qPj1eLFhc/Z3NFB51vvvlGCQkJTT0MAADwE3z11Ve67rrrLlpzRQedtm3bSvp+odxudxOPBgAA/BjBYFAJCQn2+/jFXNFBp+7jKrfbTdABAKCZ+TGXnXAxMgAAMBZBBwAAGIugAwAAjEXQAQAAxiLoAAAAYxF0AACAsQg6AADAWAQdAABgLIIOAAAwFkEHAAAYi6ADAACMRdABAADGIugAAABj1TvoFBYW6q677lJ8fLwcDofy8vJC2h0Ox3m3+fPn2zWdO3c+p33u3Lkh/ezatUuDBg1SRESEEhISNG/evHPGsmLFCvXo0UMRERFKSkrS6tWr6zsdAABgsFb1fcCJEyfUt29fPfzww7r33nvPaa+oqAjZ/+tf/6r09HSNHDky5Pjs2bM1YcIEe79t27b2z8FgUKmpqUpJSdGSJUu0e/duPfzww4qKitLEiRMlSZs3b9bo0aOVk5Ojf/qnf9KyZcs0YsQIbd++Xb17967vtMKu81OrmnoI9XZwblpTDwEAgLCqd9AZPny4hg8ffsF2j8cTsv/uu+9qyJAh6tKlS8jxtm3bnlNbZ+nSpTp9+rReffVVOZ1O3XjjjSouLtbChQvtoLNo0SINGzZM06ZNkyTNmTNH+fn5ev7557VkyZL6TgsAABioQa/Rqays1KpVq5Senn5O29y5c9WhQwf1799f8+fPV01Njd3m9/s1ePBgOZ1O+5jP51Npaam+/fZbuyYlJSWkT5/PJ7/f30CzAQAAzU29z+jUx+uvv662bdue8xHX73//ew0YMEDt27fX5s2blZWVpYqKCi1cuFCSFAgElJiYGPKY2NhYu61du3YKBAL2sR/WBAKBC46nurpa1dXV9n4wGPxZ8wMAAJe3Bg06r776qsaOHauIiIiQ45mZmfbPffr0kdPp1G9+8xvl5OTI5XI12HhycnI0a9asBusfAABcXhrso6uPPvpIpaWleuSRRy5Zm5ycrJqaGh08eFDS99f5VFZWhtTU7ddd13Ohmgtd9yNJWVlZqqqqsrevvvqqPlMCAADNTIMFnVdeeUUDBw5U3759L1lbXFysFi1aKCYmRpLk9XpVWFioM2fO2DX5+fnq3r272rVrZ9cUFBSE9JOfny+v13vB53G5XHK73SEbAAAwV72DzvHjx1VcXKzi4mJJUllZmYqLi1VeXm7XBINBrVix4rxnc/x+v/74xz9q586d+uKLL7R06VJNmTJF999/vx1ixowZI6fTqfT0dO3Zs0dvvvmmFi1aFPKR12OPPaY1a9ZowYIF2rdvn7Kzs7Vt2zZNnjy5vlMCAACGqvc1Otu2bdOQIUPs/brwMX78eOXm5kqSli9fLsuyNHr06HMe73K5tHz5cmVnZ6u6ulqJiYmaMmVKSIiJjIzU2rVrlZGRoYEDByo6OlozZ860by2XpFtvvVXLli3TjBkz9PTTT+v6669XXl7eZfEdOgAA4PLgsCzLaupBNJVgMKjIyEhVVVWF/WMsvjAQAICGUZ/3b/7WFQAAMBZBBwAAGIugAwAAjEXQAQAAxiLoAAAAYxF0AACAsQg6AADAWAQdAABgLIIOAAAwFkEHAAAYi6ADAACMRdABAADGIugAAABjEXQAAICxCDoAAMBYBB0AAGAsgg4AADAWQQcAABiLoAMAAIxF0AEAAMYi6AAAAGMRdAAAgLEIOgAAwFgEHQAAYCyCDgAAMBZBBwAAGIugAwAAjEXQAQAAxiLoAAAAYxF0AACAsQg6AADAWAQdAABgLIIOAAAwFkEHAAAYi6ADAACMRdABAADGIugAAABjEXQAAICxCDoAAMBY9Q46hYWFuuuuuxQfHy+Hw6G8vLyQ9gcffFAOhyNkGzZsWEjNkSNHNHbsWLndbkVFRSk9PV3Hjx8Pqdm1a5cGDRqkiIgIJSQkaN68eeeMZcWKFerRo4ciIiKUlJSk1atX13c6AADAYPUOOidOnFDfvn21ePHiC9YMGzZMFRUV9vbGG2+EtI8dO1Z79uxRfn6+Vq5cqcLCQk2cONFuDwaDSk1NVadOnVRUVKT58+crOztbL730kl2zefNmjR49Wunp6dqxY4dGjBihESNGqKSkpL5TAgAAhnJYlmX95Ac7HHrnnXc0YsQI+9iDDz6oo0ePnnOmp85nn32mXr166dNPP9VNN90kSVqzZo3uvPNOff3114qPj9eLL76oZ555RoFAQE6nU5L01FNPKS8vT/v27ZMkjRo1SidOnNDKlSvtvm+55Rb169dPS5Ys+VHjDwaDioyMVFVVldxu909YgQvr/NSqsPbXGA7OTWvqIQAAcEn1ef9ukGt0Nm7cqJiYGHXv3l2PPvqoDh8+bLf5/X5FRUXZIUeSUlJS1KJFC23dutWuGTx4sB1yJMnn86m0tFTffvutXZOSkhLyvD6fT36//4Ljqq6uVjAYDNkAAIC5wh50hg0bpv/6r/9SQUGB/uM//kMffvihhg8frrNnz0qSAoGAYmJiQh7TqlUrtW/fXoFAwK6JjY0Nqanbv1RNXfv55OTkKDIy0t4SEhJ+3mQBAMBlrVW4O7zvvvvsn5OSktSnTx917dpVGzdu1NChQ8P9dPWSlZWlzMxMez8YDBJ2AAAwWIPfXt6lSxdFR0dr//79kiSPx6NDhw6F1NTU1OjIkSPyeDx2TWVlZUhN3f6lauraz8flcsntdodsAADAXA0edL7++msdPnxYcXFxkiSv16ujR4+qqKjIrlm/fr1qa2uVnJxs1xQWFurMmTN2TX5+vrp376527drZNQUFBSHPlZ+fL6/X29BTAgAAzUS9g87x48dVXFys4uJiSVJZWZmKi4tVXl6u48ePa9q0adqyZYsOHjyogoIC3XPPPerWrZt8Pp8kqWfPnho2bJgmTJigTz75RB9//LEmT56s++67T/Hx8ZKkMWPGyOl0Kj09XXv27NGbb76pRYsWhXzs9Nhjj2nNmjVasGCB9u3bp+zsbG3btk2TJ08Ow7IAAAAT1DvobNu2Tf3791f//v0lSZmZmerfv79mzpypli1bateuXbr77rt1ww03KD09XQMHDtRHH30kl8tl97F06VL16NFDQ4cO1Z133qnbbrst5DtyIiMjtXbtWpWVlWngwIGaOnWqZs6cGfJdO7feequWLVuml156SX379tV///d/Ky8vT7179/456wEAAAzys75Hp7nje3RC8T06AIDmoMm/RwcAAOByQNABAADGIugAAABjEXQAAICxCDoAAMBYBB0AAGAsgg4AADAWQQcAABiLoAMAAIxF0AEAAMYi6AAAAGMRdAAAgLEIOgAAwFgEHQAAYCyCDgAAMBZBBwAAGIugAwAAjEXQAQAAxiLoAAAAYxF0AACAsQg6AADAWAQdAABgLIIOAAAwFkEHAAAYi6ADAACMRdABAADGIugAAABjEXQAAICxCDoAAMBYBB0AAGAsgg4AADAWQQcAABiLoAMAAIxF0AEAAMYi6AAAAGMRdAAAgLEIOgAAwFgEHQAAYCyCDgAAMFa9g05hYaHuuusuxcfHy+FwKC8vz247c+aMpk+frqSkJF199dWKj4/XuHHj9M0334T00blzZzkcjpBt7ty5ITW7du3SoEGDFBERoYSEBM2bN++csaxYsUI9evRQRESEkpKStHr16vpOBwAAGKzeQefEiRPq27evFi9efE7byZMntX37dv3hD3/Q9u3b9fbbb6u0tFR33333ObWzZ89WRUWFvf3ud7+z24LBoFJTU9WpUycVFRVp/vz5ys7O1ksvvWTXbN68WaNHj1Z6erp27NihESNGaMSIESopKanvlAAAgKFa1fcBw4cP1/Dhw8/bFhkZqfz8/JBjzz//vG6++WaVl5erY8eO9vG2bdvK4/Gct5+lS5fq9OnTevXVV+V0OnXjjTequLhYCxcu1MSJEyVJixYt0rBhwzRt2jRJ0pw5c5Sfn6/nn39eS5Ysqe+0AACAgRr8Gp2qqio5HA5FRUWFHJ87d646dOig/v37a/78+aqpqbHb/H6/Bg8eLKfTaR/z+XwqLS3Vt99+a9ekpKSE9Onz+eT3+y84lurqagWDwZANAACYq95ndOrju+++0/Tp0zV69Gi53W77+O9//3sNGDBA7du31+bNm5WVlaWKigotXLhQkhQIBJSYmBjSV2xsrN3Wrl07BQIB+9gPawKBwAXHk5OTo1mzZoVregAA4DLXYEHnzJkz+td//VdZlqUXX3wxpC0zM9P+uU+fPnI6nfrNb36jnJwcuVyuhhqSsrKyQp47GAwqISGhwZ4PAAA0rQYJOnUh58svv9T69etDzuacT3JysmpqanTw4EF1795dHo9HlZWVITV1+3XX9Vyo5kLX/UiSy+Vq0CAFAAAuL2G/Rqcu5Hz++edat26dOnTocMnHFBcXq0WLFoqJiZEkeb1eFRYW6syZM3ZNfn6+unfvrnbt2tk1BQUFIf3k5+fL6/WGcTYAAKA5q/cZnePHj2v//v32fllZmYqLi9W+fXvFxcXpn//5n7V9+3atXLlSZ8+eta+Zad++vZxOp/x+v7Zu3aohQ4aobdu28vv9mjJliu6//347xIwZM0azZs1Senq6pk+frpKSEi1atEjPPfec/byPPfaYbr/9di1YsEBpaWlavny5tm3bFnILOgAAuLI5LMuy6vOAjRs3asiQIeccHz9+vLKzs8+5iLjOhg0bdMcdd2j79u367W9/q3379qm6ulqJiYl64IEHlJmZGfKx0q5du5SRkaFPP/1U0dHR+t3vfqfp06eH9LlixQrNmDFDBw8e1PXXX6958+bpzjvv/NFzCQaDioyMVFVV1SU/Xquvzk+tCmt/jeHg3LSmHgIAAJdUn/fvegcdkxB0QhF0AADNQX3ev/lbVwAAwFgEHQAAYCyCDgAAMBZBBwAAGIugAwAAjEXQAQAAxiLoAAAAYxF0AACAsQg6AADAWAQdAABgLIIOAAAwFkEHAAAYi6ADAACMRdABAADGIugAAABjEXQAAICxCDoAAMBYBB0AAGAsgg4AADAWQQcAABiLoAMAAIxF0AEAAMYi6AAAAGMRdAAAgLEIOgAAwFgEHQAAYCyCDgAAMBZBBwAAGIugAwAAjEXQAQAAxiLoAAAAYxF0AACAsQg6AADAWAQdAABgLIIOAAAwFkEHAAAYi6ADAACMRdABAADGIugAAABj1TvoFBYW6q677lJ8fLwcDofy8vJC2i3L0syZMxUXF6fWrVsrJSVFn3/+eUjNkSNHNHbsWLndbkVFRSk9PV3Hjx8Pqdm1a5cGDRqkiIgIJSQkaN68eeeMZcWKFerRo4ciIiKUlJSk1atX13c6AADAYPUOOidOnFDfvn21ePHi87bPmzdPf/rTn7RkyRJt3bpVV199tXw+n7777ju7ZuzYsdqzZ4/y8/O1cuVKFRYWauLEiXZ7MBhUamqqOnXqpKKiIs2fP1/Z2dl66aWX7JrNmzdr9OjRSk9P144dOzRixAiNGDFCJSUl9Z0SAAAwlMOyLOsnP9jh0DvvvKMRI0ZI+v5sTnx8vKZOnaonnnhCklRVVaXY2Fjl5ubqvvvu02effaZevXrp008/1U033SRJWrNmje688059/fXXio+P14svvqhnnnlGgUBATqdTkvTUU08pLy9P+/btkySNGjVKJ06c0MqVK+3x3HLLLerXr5+WLFnyo8YfDAYVGRmpqqoqud3un7oM59X5qVVh7a8xHJyb1tRDAADgkurz/h3Wa3TKysoUCASUkpJiH4uMjFRycrL8fr8kye/3Kyoqyg45kpSSkqIWLVpo69atds3gwYPtkCNJPp9PpaWl+vbbb+2aHz5PXU3d85xPdXW1gsFgyAYAAMwV1qATCAQkSbGxsSHHY2Nj7bZAIKCYmJiQ9latWql9+/YhNefr44fPcaGauvbzycnJUWRkpL0lJCTUd4oAAKAZuaLuusrKylJVVZW9ffXVV009JAAA0IDCGnQ8Ho8kqbKyMuR4ZWWl3ebxeHTo0KGQ9pqaGh05ciSk5nx9/PA5LlRT134+LpdLbrc7ZAMAAOYKa9BJTEyUx+NRQUGBfSwYDGrr1q3yer2SJK/Xq6NHj6qoqMiuWb9+vWpra5WcnGzXFBYW6syZM3ZNfn6+unfvrnbt2tk1P3yeupq65wEAAKh30Dl+/LiKi4tVXFws6fsLkIuLi1VeXi6Hw6HHH39c//Zv/6b33ntPu3fv1rhx4xQfH2/fmdWzZ08NGzZMEyZM0CeffKKPP/5YkydP1n333af4+HhJ0pgxY+R0OpWenq49e/bozTff1KJFi5SZmWmP47HHHtOaNWu0YMEC7du3T9nZ2dq2bZsmT57881cFAAAYoVV9H7Bt2zYNGTLE3q8LH+PHj1dubq6efPJJnThxQhMnTtTRo0d12223ac2aNYqIiLAfs3TpUk2ePFlDhw5VixYtNHLkSP3pT3+y2yMjI7V27VplZGRo4MCBio6O1syZM0O+a+fWW2/VsmXLNGPGDD399NO6/vrrlZeXp969e/+khQAAAOb5Wd+j09zxPTqh+B4dAEBz0GTfowMAAHA5IegAAABjEXQAAICxCDoAAMBYBB0AAGAsgg4AADAWQQcAABiLoAMAAIxF0AEAAMYi6AAAAGMRdAAAgLEIOgAAwFgEHQAAYCyCDgAAMBZBBwAAGIugAwAAjEXQAQAAxiLoAAAAYxF0AACAsQg6AADAWAQdAABgLIIOAAAwFkEHAAAYi6ADAACMRdABAADGIugAAABjEXQAAICxCDoAAMBYBB0AAGAsgg4AADAWQQcAABiLoAMAAIxF0AEAAMYi6AAAAGMRdAAAgLEIOgAAwFgEHQAAYCyCDgAAMBZBBwAAGCvsQadz585yOBznbBkZGZKkO+6445y2SZMmhfRRXl6utLQ0tWnTRjExMZo2bZpqampCajZu3KgBAwbI5XKpW7duys3NDfdUAABAM9cq3B1++umnOnv2rL1fUlKif/zHf9S//Mu/2McmTJig2bNn2/tt2rSxfz579qzS0tLk8Xi0efNmVVRUaNy4cbrqqqv07//+75KksrIypaWladKkSVq6dKkKCgr0yCOPKC4uTj6fL9xTAgAAzVTYg861114bsj937lx17dpVt99+u32sTZs28ng853382rVrtXfvXq1bt06xsbHq16+f5syZo+nTpys7O1tOp1NLlixRYmKiFixYIEnq2bOnNm3apOeee46gAwAAbA16jc7p06f1l7/8RQ8//LAcDod9fOnSpYqOjlbv3r2VlZWlkydP2m1+v19JSUmKjY21j/l8PgWDQe3Zs8euSUlJCXkun88nv99/0fFUV1crGAyGbAAAwFxhP6PzQ3l5eTp69KgefPBB+9iYMWPUqVMnxcfHa9euXZo+fbpKS0v19ttvS5ICgUBIyJFk7wcCgYvWBINBnTp1Sq1btz7veHJycjRr1qxwTQ8AAFzmGjTovPLKKxo+fLji4+PtYxMnTrR/TkpKUlxcnIYOHaoDBw6oa9euDTkcZWVlKTMz094PBoNKSEho0OcEAABNp8GCzpdffql169bZZ2ouJDk5WZK0f/9+de3aVR6PR5988klITWVlpSTZ1/V4PB772A9r3G73Bc/mSJLL5ZLL5ar3XAAAQPPUYNfovPbaa4qJiVFaWtpF64qLiyVJcXFxkiSv16vdu3fr0KFDdk1+fr7cbrd69epl1xQUFIT0k5+fL6/XG8YZAACA5q5Bgk5tba1ee+01jR8/Xq1a/f+TRgcOHNCcOXNUVFSkgwcP6r333tO4ceM0ePBg9enTR5KUmpqqXr166YEHHtDOnTv1wQcfaMaMGcrIyLDPxkyaNElffPGFnnzySe3bt08vvPCC3nrrLU2ZMqUhpgMAAJqpBgk669atU3l5uR5++OGQ406nU+vWrVNqaqp69OihqVOnauTIkXr//fftmpYtW2rlypVq2bKlvF6v7r//fo0bNy7ke3cSExO1atUq5efnq2/fvlqwYIFefvllbi0HAAAhHJZlWU09iKYSDAYVGRmpqqoqud3usPbd+alVYe2vMRyce/GPGQEAuBzU5/2bv3UFAACMRdABAADGIugAAABjEXQAAICxCDoAAMBYBB0AAGAsgg4AADAWQQcAABiLoAMAAIxF0AEAAMYi6AAAAGMRdAAAgLEIOgAAwFgEHQAAYCyCDgAAMBZBBwAAGIugAwAAjEXQAQAAxiLoAAAAYxF0AACAsQg6AADAWAQdAABgLIIOAAAwFkEHAAAYi6ADAACMRdABAADGIugAAABjEXQAAICxCDoAAMBYBB0AAGAsgg4AADAWQQcAABiLoAMAAIxF0AEAAMYi6AAAAGMRdAAAgLFaNfUAcPno/NSqph5CvR2cm9bUQwAAXMY4owMAAIwV9qCTnZ0th8MRsvXo0cNu/+6775SRkaEOHTrommuu0ciRI1VZWRnSR3l5udLS0tSmTRvFxMRo2rRpqqmpCanZuHGjBgwYIJfLpW7duik3NzfcUwEAAM1cg5zRufHGG1VRUWFvmzZtstumTJmi999/XytWrNCHH36ob775Rvfee6/dfvbsWaWlpen06dPavHmzXn/9deXm5mrmzJl2TVlZmdLS0jRkyBAVFxfr8ccf1yOPPKIPPvigIaYDAACaqQa5RqdVq1byeDznHK+qqtIrr7yiZcuW6R/+4R8kSa+99pp69uypLVu26JZbbtHatWu1d+9erVu3TrGxserXr5/mzJmj6dOnKzs7W06nU0uWLFFiYqIWLFggSerZs6c2bdqk5557Tj6fryGmBAAAmqEGOaPz+eefKz4+Xl26dNHYsWNVXl4uSSoqKtKZM2eUkpJi1/bo0UMdO3aU3++XJPn9fiUlJSk2Ntau8fl8CgaD2rNnj13zwz7qaur6AAAAkBrgjE5ycrJyc3PVvXt3VVRUaNasWRo0aJBKSkoUCATkdDoVFRUV8pjY2FgFAgFJUiAQCAk5de11bRerCQaDOnXqlFq3bn3esVVXV6u6utreDwaDP2uuAADg8hb2oDN8+HD75z59+ig5OVmdOnXSW2+9dcEA0lhycnI0a9asJh0DAABoPA1+e3lUVJRuuOEG7d+/Xx6PR6dPn9bRo0dDaiorK+1rejwezzl3YdXtX6rG7XZfNExlZWWpqqrK3r766qufOz0AAHAZa/Cgc/z4cR04cEBxcXEaOHCgrrrqKhUUFNjtpaWlKi8vl9frlSR5vV7t3r1bhw4dsmvy8/PldrvVq1cvu+aHfdTV1PVxIS6XS263O2QDAADmCnvQeeKJJ/Thhx/q4MGD2rx5s37961+rZcuWGj16tCIjI5Wenq7MzExt2LBBRUVFeuihh+T1enXLLbdIklJTU9WrVy898MAD2rlzpz744APNmDFDGRkZcrlckqRJkybpiy++0JNPPql9+/bphRde0FtvvaUpU6aEezoAAKAZC/s1Ol9//bVGjx6tw4cP69prr9Vtt92mLVu26Nprr5UkPffcc2rRooVGjhyp6upq+Xw+vfDCC/bjW7ZsqZUrV+rRRx+V1+vV1VdfrfHjx2v27Nl2TWJiolatWqUpU6Zo0aJFuu666/Tyyy9zazkAAAjhsCzLaupBNJVgMKjIyEhVVVWF/WOs5vh3o5oj/tYVAFx56vP+zd+6AgAAxiLoAAAAYxF0AACAsQg6AADAWAQdAABgLIIOAAAwFkEHAAAYi6ADAACMRdABAADGIugAAABjEXQAAICxCDoAAMBYBB0AAGAsgg4AADAWQQcAABiLoAMAAIxF0AEAAMYi6AAAAGMRdAAAgLEIOgAAwFgEHQAAYCyCDgAAMBZBBwAAGIugAwAAjEXQAQAAxiLoAAAAYxF0AACAsQg6AADAWAQdAABgLIIOAAAwFkEHAAAYi6ADAACMRdABAADGIugAAABjEXQAAICxCDoAAMBYBB0AAGAsgg4AADAWQQcAABgr7EEnJydHv/zlL9W2bVvFxMRoxIgRKi0tDam544475HA4QrZJkyaF1JSXlystLU1t2rRRTEyMpk2bppqampCajRs3asCAAXK5XOrWrZtyc3PDPR0AANCMhT3ofPjhh8rIyNCWLVuUn5+vM2fOKDU1VSdOnAipmzBhgioqKuxt3rx5dtvZs2eVlpam06dPa/PmzXr99deVm5urmTNn2jVlZWVKS0vTkCFDVFxcrMcff1yPPPKIPvjgg3BPCQAANFOtwt3hmjVrQvZzc3MVExOjoqIiDR482D7epk0beTye8/axdu1a7d27V+vWrVNsbKz69eunOXPmaPr06crOzpbT6dSSJUuUmJioBQsWSJJ69uypTZs26bnnnpPP5wv3tAAAQDPU4NfoVFVVSZLat28fcnzp0qWKjo5W7969lZWVpZMnT9ptfr9fSUlJio2NtY/5fD4Fg0Ht2bPHrklJSQnp0+fzye/3X3As1dXVCgaDIRsAADBX2M/o/FBtba0ef/xx/epXv1Lv3r3t42PGjFGnTp0UHx+vXbt2afr06SotLdXbb78tSQoEAiEhR5K9HwgELloTDAZ16tQptW7d+pzx5OTkaNasWWGdIwAAuHw1aNDJyMhQSUmJNm3aFHJ84sSJ9s9JSUmKi4vT0KFDdeDAAXXt2rXBxpOVlaXMzEx7PxgMKiEhocGeDwAANK0G++hq8uTJWrlypTZs2KDrrrvuorXJycmSpP3790uSPB6PKisrQ2rq9uuu67lQjdvtPu/ZHElyuVxyu90hGwAAMFfYg45lWZo8ebLeeecdrV+/XomJiZd8THFxsSQpLi5OkuT1erV7924dOnTIrsnPz5fb7VavXr3smoKCgpB+8vPz5fV6wzQTAADQ3IU96GRkZOgvf/mLli1bprZt2yoQCCgQCOjUqVOSpAMHDmjOnDkqKirSwYMH9d5772ncuHEaPHiw+vTpI0lKTU1Vr1699MADD2jnzp364IMPNGPGDGVkZMjlckmSJk2apC+++EJPPvmk9u3bpxdeeEFvvfWWpkyZEu4pAQCAZirsQefFF19UVVWV7rjjDsXFxdnbm2++KUlyOp1at26dUlNT1aNHD02dOlUjR47U+++/b/fRsmVLrVy5Ui1btpTX69X999+vcePGafbs2XZNYmKiVq1apfz8fPXt21cLFizQyy+/zK3lAADA5rAsy2rqQTSVYDCoyMhIVVVVhf16nc5PrQprfzi/g3PTmnoIAIBGVp/3b/7WFQAAMBZBBwAAGIugAwAAjEXQAQAAxiLoAAAAYxF0AACAsQg6AADAWAQdAABgLIIOAAAwFkEHAAAYi6ADAACMRdABAADGIugAAABjEXQAAICxCDoAAMBYBB0AAGCsVk09AODn6PzUqqYeQr0dnJvW1EMAgCsGZ3QAAICxCDoAAMBYBB0AAGAsgg4AADAWQQcAABiLoAMAAIxF0AEAAMYi6AAAAGMRdAAAgLEIOgAAwFgEHQAAYCyCDgAAMBZBBwAAGIugAwAAjEXQAQAAxiLoAAAAY7Vq6gEAV5rOT61q6iH8JAfnpjX1EACg3jijAwAAjEXQAQAAxiLoAAAAYxF0AACAsQg6AADAWM0+6CxevFidO3dWRESEkpOT9cknnzT1kAAAwGWiWQedN998U5mZmXr22We1fft29e3bVz6fT4cOHWrqoQEAgMtAsw46Cxcu1IQJE/TQQw+pV69eWrJkidq0aaNXX321qYcGAAAuA832CwNPnz6toqIiZWVl2cdatGihlJQU+f3+8z6murpa1dXV9n5VVZUkKRgMhn18tdUnw94n0JQ6TlnR1EOot5JZvqYeAoAGUPe+bVnWJWubbdD5+9//rrNnzyo2NjbkeGxsrPbt23fex+Tk5GjWrFnnHE9ISGiQMQJoWpF/bOoRAGhIx44dU2Rk5EVrmm3Q+SmysrKUmZlp79fW1urIkSPq0KGDHA7Hz+4/GAwqISFBX331ldxu98/uDxfHejcu1rvxsNaNi/VuXOFYb8uydOzYMcXHx1+yttkGnejoaLVs2VKVlZUhxysrK+XxeM77GJfLJZfLFXIsKioq7GNzu938x9KIWO/GxXo3Hta6cbHejevnrvelzuTUabYXIzudTg0cOFAFBQX2sdraWhUUFMjr9TbhyAAAwOWi2Z7RkaTMzEyNHz9eN910k26++Wb98Y9/1IkTJ/TQQw819dAAAMBloFkHnVGjRulvf/ubZs6cqUAgoH79+mnNmjXnXKDcWFwul5599tlzPh5Dw2C9Gxfr3XhY68bFejeuxl5vh/Vj7s0CAABohprtNToAAACXQtABAADGIugAAABjEXQAAICxCDphtHjxYnXu3FkRERFKTk7WJ5980tRDanays7PlcDhCth49etjt3333nTIyMtShQwddc801Gjly5DlfGlleXq60tDS1adNGMTExmjZtmmpqahp7KpelwsJC3XXXXYqPj5fD4VBeXl5Iu2VZmjlzpuLi4tS6dWulpKTo888/D6k5cuSIxo4dK7fbraioKKWnp+v48eMhNbt27dKgQYMUERGhhIQEzZs3r6Gndtm51Fo/+OCD5/yuDxs2LKSGtf5xcnJy9Mtf/lJt27ZVTEyMRowYodLS0pCacL12bNy4UQMGDJDL5VK3bt2Um5vb0NO77PyY9b7jjjvO+f2eNGlSSE2jrbeFsFi+fLnldDqtV1991dqzZ481YcIEKyoqyqqsrGzqoTUrzz77rHXjjTdaFRUV9va3v/3Nbp80aZKVkJBgFRQUWNu2bbNuueUW69Zbb7Xba2pqrN69e1spKSnWjh07rNWrV1vR0dFWVlZWU0znsrN69WrrmWeesd5++21LkvXOO++EtM+dO9eKjIy08vLyrJ07d1p33323lZiYaJ06dcquGTZsmNW3b19ry5Yt1kcffWR169bNGj16tN1eVVVlxcbGWmPHjrVKSkqsN954w2rdurX1n//5n401zcvCpdZ6/Pjx1rBhw0J+148cORJSw1r/OD6fz3rttdeskpISq7i42Lrzzjutjh07WsePH7drwvHa8cUXX1ht2rSxMjMzrb1791p//vOfrZYtW1pr1qxp1Pk2tR+z3rfffrs1YcKEkN/vqqoqu70x15ugEyY333yzlZGRYe+fPXvWio+Pt3JycppwVM3Ps88+a/Xt2/e8bUePHrWuuuoqa8WKFfaxzz77zJJk+f1+y7K+f3Np0aKFFQgE7JoXX3zRcrvdVnV1dYOOvbn5v2++tbW1lsfjsebPn28fO3r0qOVyuaw33njDsizL2rt3ryXJ+vTTT+2av/71r5bD4bD+53/+x7Isy3rhhResdu3ahaz39OnTre7duzfwjC5fFwo699xzzwUfw1r/dIcOHbIkWR9++KFlWeF77XjyySetG2+8MeS5Ro0aZfl8voae0mXt/663ZX0fdB577LELPqYx15uPrsLg9OnTKioqUkpKin2sRYsWSklJkd/vb8KRNU+ff/654uPj1aVLF40dO1bl5eWSpKKiIp05cyZknXv06KGOHTva6+z3+5WUlBTypZE+n0/BYFB79uxp3Ik0M2VlZQoEAiHrGxkZqeTk5JD1jYqK0k033WTXpKSkqEWLFtq6datdM3jwYDmdTrvG5/OptLRU3377bSPNpnnYuHGjYmJi1L17dz366KM6fPiw3cZa/3RVVVWSpPbt20sK32uH3+8P6aOu5kp/nf+/611n6dKlio6OVu/evZWVlaWTJ0/abY253s36m5EvF3//+9919uzZc76ROTY2Vvv27WuiUTVPycnJys3NVffu3VVRUaFZs2Zp0KBBKikpUSAQkNPpPOcPscbGxioQCEiSAoHAef8d6tpwYXXrc771++H6xsTEhLS3atVK7du3D6lJTEw8p4+6tnbt2jXI+JubYcOG6d5771ViYqIOHDigp59+WsOHD5ff71fLli1Z65+otrZWjz/+uH71q1+pd+/ekhS2144L1QSDQZ06dUqtW7duiCld1s633pI0ZswYderUSfHx8dq1a5emT5+u0tJSvf3225Iad70JOrisDB8+3P65T58+Sk5OVqdOnfTWW29dkS8iMNd9991n/5yUlKQ+ffqoa9eu2rhxo4YOHdqEI2veMjIyVFJSok2bNjX1UK4IF1rviRMn2j8nJSUpLi5OQ4cO1YEDB9S1a9dGHSMfXYVBdHS0WrZsec4V/JWVlfJ4PE00KjNERUXphhtu0P79++XxeHT69GkdPXo0pOaH6+zxeM7771DXhgurW5+L/R57PB4dOnQopL2mpkZHjhzh3+Bn6tKli6Kjo7V//35JrPVPMXnyZK1cuVIbNmzQddddZx8P12vHhWrcbvcV+T9iF1rv80lOTpakkN/vxlpvgk4YOJ1ODRw4UAUFBfax2tpaFRQUyOv1NuHImr/jx4/rwIEDiouL08CBA3XVVVeFrHNpaanKy8vtdfZ6vdq9e3fIG0R+fr7cbrd69erV6ONvThITE+XxeELWNxgMauvWrSHre/ToURUVFdk169evV21trf1C5vV6VVhYqDNnztg1+fn56t69+xX5UcqP9fXXX+vw4cOKi4uTxFrXh2VZmjx5st555x2tX7/+nI/zwvXa4fV6Q/qoq7nSXucvtd7nU1xcLEkhv9+Ntt71unQZF7R8+XLL5XJZubm51t69e62JEydaUVFRIVeU49KmTp1qbdy40SorK7M+/vhjKyUlxYqOjrYOHTpkWdb3t4h27NjRWr9+vbVt2zbL6/VaXq/XfnzdLYupqalWcXGxtWbNGuvaa6/l9vL/dezYMWvHjh3Wjh07LEnWwoULrR07dlhffvmlZVnf314eFRVlvfvuu9auXbuse+6557y3l/fv39/aunWrtWnTJuv6668PueX56NGjVmxsrPXAAw9YJSUl1vLly602bdpccbc8X2ytjx07Zj3xxBOW3++3ysrKrHXr1lkDBgywrr/+euu7776z+2Ctf5xHH33UioyMtDZu3BhyO/PJkyftmnC8dtTd7jxt2jTrs88+sxYvXnxF3l5+qfXev3+/NXv2bGvbtm1WWVmZ9e6771pdunSxBg8ebPfRmOtN0AmjP//5z1bHjh0tp9Np3XzzzdaWLVuaekjNzqhRo6y4uDjL6XRav/jFL6xRo0ZZ+/fvt9tPnTpl/fa3v7XatWtntWnTxvr1r39tVVRUhPRx8OBBa/jw4Vbr1q2t6Ohoa+rUqdaZM2caeyqXpQ0bNliSztnGjx9vWdb3t5j/4Q9/sGJjYy2Xy2UNHTrUKi0tDenj8OHD1ujRo61rrrnGcrvd1kMPPWQdO3YspGbnzp3WbbfdZrlcLusXv/iFNXfu3Maa4mXjYmt98uRJKzU11br22mutq666yurUqZM1YcKEc/7HiLX+cc63zpKs1157za4J12vHhg0brH79+llOp9Pq0qVLyHNcKS613uXl5dbgwYOt9u3bWy6Xy+rWrZs1bdq0kO/RsazGW2/H/w4aAADAOFyjAwAAjEXQAQAAxiLoAAAAYxF0AACAsQg6AADAWAQdAABgLIIOAAAwFkEHAAAYi6ADAACMRdABAADGIugAAABjEXQAAICx/h/RF/3kKoxMkQAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "### Get a grasp of review lengths for training in batches\n",
        "\n",
        "train_reviews_length = [len(re) for re in train_reviews_encoded]\n",
        "\n",
        "plt.hist(train_reviews_length)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "BohoevF3o3Te",
        "outputId": "36baf210-69cb-407a-fe8a-fda98e807e3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean of the review length: 233\n",
            "25th percentile of the review length: 127.0\n",
            "50th percentile of the review length: 174.0\n",
            "75th percentile of the review length: 284.0\n"
          ]
        }
      ],
      "source": [
        "### Get basic statistics\n",
        "\n",
        "print(\"Mean of the review length:\", int(np.mean(train_reviews_length)))\n",
        "print(\"25th percentile of the review length:\", np.percentile(train_reviews_length, 25))\n",
        "print(\"50th percentile of the review length:\", np.percentile(train_reviews_length, 50))\n",
        "print(\"75th percentile of the review length:\", np.percentile(train_reviews_length, 75))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "B-1AVPnso3Ra"
      },
      "outputs": [],
      "source": [
        "### Guess a review length of 256 should be good enough\n",
        "### Remove review of length 0, if there\n",
        "\n",
        "train_reviews_encoded = [train_reviews_encoded[index] for index, length in enumerate(train_reviews_length) if length >= SEQUENCE_MIN_CUTOFF_LENGTH]\n",
        "train_ratings_encoded = [train_ratings_encoded[index] for index, length in enumerate(train_reviews_length) if length >= SEQUENCE_MIN_CUTOFF_LENGTH]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "bGwD3J7yo3PO"
      },
      "outputs": [],
      "source": [
        "### For reviews shorter than SEQUENCE_LENGTH, we will pad with 0s. For reviews longer than seq_length we will truncate them to the first SEQUENCE_LENGTH words. SEQUENCE_LENGTH is same as number of timesteps in LSTM\n",
        "\n",
        "# pad/ truncate the reviews to a uniform size of SEQUENCE_LENGTH. Output id array of shape #num_reviews * SEQUENCE_LENGTH\n",
        "train_reviews_encoded_arr = pad_and_truncate_reviews(train_reviews_encoded, SEQUENCE_MAX_CUTOFF_LENGTH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIlZvAYwpAW_"
      },
      "source": [
        "## 04. Train validation split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "LnwDFBQBo2nd"
      },
      "outputs": [],
      "source": [
        "### As first 12500 reviews are positive and next 12500 reviews are negative. I have to uniquely select the reviews to ensure 50-50 balance of reviews in train and validation\n",
        "\n",
        "split_frac = 0.8\n",
        "\n",
        "train_index = np.concatenate(\n",
        "    (random.choice(list(range(0,12500)), size = int(split_frac*12500), replace= False),\n",
        "     random.choice(list(range(12500,25000)), size = int(split_frac*12500), replace= False),\n",
        "    ), axis = 0)\n",
        "\n",
        "validation_index = np.setdiff1d(np.array(list(range(0,25000))), train_index)\n",
        "\n",
        "\n",
        "# Get the train and validation dataset\n",
        "train_reviews_encodedX = np.take(train_reviews_encoded_arr, train_index, axis= 0)\n",
        "train_ratings_encodedy = np.take(np.array(train_ratings_encoded, dtype = int), train_index, axis= 0)\n",
        "\n",
        "valid_reviews_encodedX = np.take(train_reviews_encoded_arr, validation_index, axis= 0)\n",
        "valid_ratings_encodedy = np.take(np.array(train_ratings_encoded, dtype = int), validation_index, axis= 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Q6ukJP8eo2j9"
      },
      "outputs": [],
      "source": [
        "# create custom Dataset and Dataloader for train and validation data\n",
        "\n",
        "train_dataset = SentimentDataset(train_reviews_encodedX, train_ratings_encodedy)\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "\n",
        "valid_dataset = SentimentDataset(valid_reviews_encodedX, valid_ratings_encodedy)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "YGsQq7RDevEA"
      },
      "outputs": [],
      "source": [
        "# Dump numpy array to npy file to train on colab. SKip if system has GPU\n",
        "np.save(\"train_reviews_encodedX.npy\", train_reviews_encodedX)\n",
        "np.save(\"train_ratings_encodedy.npy\", train_ratings_encodedy)\n",
        "np.save(\"valid_reviews_encodedX.npy\", valid_reviews_encodedX)\n",
        "np.save(\"valid_ratings_encodedy.npy\", valid_ratings_encodedy)\n",
        "\n",
        "train_reviews_encodedX = np.load(\"train_reviews_encodedX.npy\")\n",
        "train_ratings_encodedy = np.load(\"train_ratings_encodedy.npy\")\n",
        "valid_reviews_encodedX = np.load(\"valid_reviews_encodedX.npy\")\n",
        "valid_ratings_encodedy = np.load(\"valid_ratings_encodedy.npy\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_hLxzyUpErU"
      },
      "source": [
        "## 05. Create a model instanse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "VP2Q3D6Lo2iQ"
      },
      "outputs": [],
      "source": [
        "model = SentimentLSTM(vocab_size = len(vocab_to_int),\n",
        "                      output_size = OUTPUT_SIZE,\n",
        "                      embedding_dim = EMBEDDING_DIM,\n",
        "                      hidden_dim = LSTM_HIDDEN_DIM,\n",
        "                      n_layers = LSTM_NLAYERS,\n",
        "                      drop_prob=DROP_PROP)\n",
        "\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAEQ1ke7evEA"
      },
      "source": [
        "## 06. Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "mPchbET_o2ev"
      },
      "outputs": [],
      "source": [
        "\n",
        "# loss and optimization functions\n",
        "lr= LEARNING_RATE\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "# training params\n",
        "epochs = EPOCHS # 3-4 is approx where I noticed the validation loss stop decreasing\n",
        "clip= CLIP # gradient clipping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "AnVO6veXo2c8"
      },
      "outputs": [],
      "source": [
        "# train loops\n",
        "\n",
        "epoch_tr_loss,epoch_vl_loss = [],[]\n",
        "epoch_tr_acc,epoch_vl_acc = [],[]\n",
        "\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    train_losses = []\n",
        "    train_acc = 0.0\n",
        "    model.train()\n",
        "    # initialize hidden state\n",
        "    h = model.init_hidden(BATCH_SIZE)\n",
        "    for inputs, labels in train_loader:\n",
        "\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        # Creating new variables for the hidden state, otherwise\n",
        "        # we'd backprop through the entire training history\n",
        "        h = tuple([each.data for each in h])\n",
        "\n",
        "        model.zero_grad()\n",
        "        output,h = model(inputs,h)\n",
        "\n",
        "        # calculate the loss and perform backprop\n",
        "        loss = criterion(output.squeeze(), labels.float())\n",
        "        loss.backward()\n",
        "        train_losses.append(loss.item())\n",
        "        # calculating accuracy\n",
        "        acc = accuracy(output,labels)\n",
        "        train_acc += acc\n",
        "        #`clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "\n",
        "    val_h = model.init_hidden(BATCH_SIZE)\n",
        "    val_losses = []\n",
        "    val_acc = 0.0\n",
        "    model.eval()\n",
        "    for inputs, labels in valid_loader:\n",
        "            val_h = tuple([each.data for each in val_h])\n",
        "\n",
        "\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "\n",
        "            output, val_h = model(inputs, val_h)\n",
        "            val_loss = criterion(output.squeeze(), labels.float())\n",
        "\n",
        "\n",
        "            val_losses.append(val_loss.item())\n",
        "\n",
        "            acc = accuracy(output,labels)\n",
        "            val_acc += acc\n",
        "\n",
        "    epoch_train_loss = np.mean(train_losses)\n",
        "    epoch_val_loss = np.mean(val_losses)\n",
        "    epoch_train_acc = train_acc/len(train_loader.dataset)\n",
        "    epoch_val_acc = val_acc/len(valid_loader.dataset)\n",
        "    epoch_tr_loss.append(epoch_train_loss)\n",
        "    epoch_vl_loss.append(epoch_val_loss)\n",
        "    epoch_tr_acc.append(epoch_train_acc)\n",
        "    epoch_vl_acc.append(epoch_val_acc)\n",
        "    print(f'Epoch {epoch+1}')\n",
        "    print(f'train_loss : {epoch_train_loss} val_loss : {epoch_val_loss}')\n",
        "    print(f'train_accuracy : {epoch_train_acc*100} val_accuracy : {epoch_val_acc*100}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TF9RkvmXevEA"
      },
      "source": [
        "## 07. Model weight saving & Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "-5hhTs2nevEA"
      },
      "outputs": [],
      "source": [
        "# save the model weights. Saved on GPU and to be loaded on GPU\n",
        "\n",
        "torch.save(model.state_dict(), \"LSTM_Sentimentanalysis.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "hqxS_sc0evEA"
      },
      "outputs": [],
      "source": [
        "# load the model weights\n",
        "test_model = SentimentLSTM(vocab_size = len(vocab_to_int) +1, # len(vocab_to_int) +1 for zero,\n",
        "                      output_size = OUTPUT_SIZE,\n",
        "                      embedding_dim = EMBEDDING_DIM,\n",
        "                      hidden_dim = LSTM_HIDDEN_DIM,\n",
        "                      n_layers = LSTM_NLAYERS,\n",
        "                      drop_prob=DROP_PROP)\n",
        "\n",
        "\n",
        "test_model.load_state_dict(torch.load(\"LSTM_Sentimentanalysis.pth\", map_location=device))\n",
        "print(test_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "7QMXIeHVevEB"
      },
      "outputs": [],
      "source": [
        "# test on a sample review\n",
        "\n",
        "neg_review = \"This is a pale imitation of 'Officer and a Gentleman.' There is NO chemistry between Kutcher and the unknown woman who plays his love interest. The dialog is wooden, the situations hackneyed. It's too long and the climax is anti-climactic(!). I love the USCG, its men and women are fearless and tough. The action scenes are awesome, but this movie doesn't do much for recruiting, I fear. The script is formulaic, but confusing. Kutcher's character is trying to redeem himself for an accident that wasn't his fault? Costner's is raging against the dying of the light, but why? His 'conflict' with his wife is about as deep as a mud puddle. I saw this sneak preview for free and certainly felt I got my money's worth.\"\n",
        "\n",
        "pos_review = \"I went and saw this movie last night after being coaxed to by a few friends of mine. I'll admit that I was reluctant to see it because from what I knew of Ashton Kutcher he was only able to do comedy. I was wrong. Kutcher played the character of Jake Fischer very well, and Kevin Costner played Ben Randall with such professionalism. The sign of a good movie is that it can toy with our emotions. This one did exactly that. The entire theater (which was sold out) was overcome by laughter during the first half of the movie, and were moved to tears during the second half. While exiting the theater I not only saw many women in tears, but many full grown men as well, trying desperately not to let anyone see them crying. This movie was great, and I suggest that you go see it before you judge.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HfVCRWr3evEB",
        "outputId": "1d5a5a0d-eb0f-409b-d747-b471092f4672"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment score for negative reviw is 0.39911898970603943\n"
          ]
        }
      ],
      "source": [
        "# sentiment for negative review\n",
        "review_encoded = process_test_reviewx(neg_review, vocab_to_int_mapper = vocab_to_int)\n",
        "\n",
        "print(\"Sentiment score for negative reviw is\" , predict_sentiment(review_encoded, model = test_model, device = device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXpkS7JZevEB",
        "outputId": "75a24fd1-5cb3-4f15-8a85-1331da37a0bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment score for positive reviw is 0.9870518445968628\n"
          ]
        }
      ],
      "source": [
        "# sentiment for positive review\n",
        "review_encoded = process_test_reviewx(pos_review, vocab_to_int_mapper = vocab_to_int)\n",
        "\n",
        "print(\"Sentiment score for positive reviw is\" , predict_sentiment(review_encoded, model = test_model, device = device))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}